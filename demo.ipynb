{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install audiolm-pytorch x-clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "from audiolm_pytorch.data import SoundDataset\n",
    "from audiolm_pytorch.hubert_kmeans import HubertWithKmeans\n",
    "\n",
    "from spear_tts_pytorch.spear_tts_pytorch import TextToSemantic\n",
    "from spear_tts_pytorch.trainer import SpeechSpeechPretrainer\n",
    "\n",
    "from torchaudio import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_ckpt = 'hubert/hubert_base_ls960.pt'\n",
    "hubert_quantizer = f'hubert/hubert_base_ls960_L9_km500.bin'\n",
    "\n",
    "if not os.path.isdir(\"hubert\"):\n",
    "  os.makedirs(\"hubert\")\n",
    "if not os.path.isfile(hubert_ckpt):\n",
    "  hubert_ckpt_download = f\"https://dl.fbaipublicfiles.com/{hubert_ckpt}\"\n",
    "  urllib.request.urlretrieve(hubert_ckpt_download, f\"./{hubert_ckpt}\")\n",
    "if not os.path.isfile(hubert_quantizer):\n",
    "  hubert_quantizer_download = f\"https://dl.fbaipublicfiles.com/{hubert_quantizer}\"\n",
    "  urllib.request.urlretrieve(hubert_quantizer_download, f\"./{hubert_quantizer}\")\n",
    "\n",
    "wav2vec = HubertWithKmeans(\n",
    "    checkpoint_path = './hubert/hubert_base_ls960.pt',\n",
    "    kmeans_path = './hubert/hubert_base_ls960_L9_km500.bin',\n",
    "    target_sample_hz = 24_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset if needed.\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.makedirs('data')\n",
    "\n",
    "ds = datasets.LIBRITTS(\n",
    "    root = 'data',\n",
    "    url = 'dev-clean',\n",
    "    download = True\n",
    ")\n",
    "\n",
    "dataset_folder = 'data/LibriTTS/dev-clean'\n",
    "data_max_length_seconds = 3\n",
    "\n",
    "dataset = SoundDataset(\n",
    "    dataset_folder,\n",
    "    max_length = int(data_max_length_seconds * wav2vec.target_sample_hz),\n",
    "    target_sample_hz = wav2vec.target_sample_hz,\n",
    "    seq_len_multiple_of = wav2vec.seq_len_multiple_of\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5-small from Table 9 in the paper.\n",
    "\n",
    "text_to_semantic_model = TextToSemantic(\n",
    "    dim = 256,\n",
    "    num_text_token_ids = 32100,\n",
    "    source_depth = 6,\n",
    "    target_depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64,\n",
    "    wav2vec = wav2vec,\n",
    "    num_semantic_token_ids = wav2vec.codebook_size,\n",
    "    attn_dropout = 0.5,\n",
    "    ff_mult = 2,\n",
    "    ff_dropout = 0.5\n",
    ")\n",
    "\n",
    "trainer = SpeechSpeechPretrainer(\n",
    "    model = text_to_semantic_model,\n",
    "    wav2vec = wav2vec,\n",
    "    dataset = dataset,\n",
    "    batch_size = 16,\n",
    "    grad_accum_every = 4,\n",
    "    lr = 2e-4,\n",
    "    num_train_steps = 100_000\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
